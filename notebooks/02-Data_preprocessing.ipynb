{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation\n",
    "Before starting to train the model, some steps need to be done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. ROI Extraction\n",
    "The images are large in size (above 2000 x 2000 pixels), so it is better to extract the area that is important to us by using a cropping function. This cropping process should be applied to both the image and the respective masks.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-11.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# Input and output directories\n",
    "raw_imgs = Path(\"../images/raw_images\").glob(\"*.jpg\")\n",
    "raw_labels = Path(\"../images/raw_labels\").glob(\"*.png\")\n",
    "cropped_img_dir = Path(\"../images/\") / \"cropped_images\"\n",
    "cropped_label_dir = Path(\"../images/\") / \"cropped_labels\"\n",
    "cropped_img_dir.mkdir(exist_ok=True)\n",
    "cropped_label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def crop_imgs(input_imgs, output_dir) -> None:\n",
    "   for img_path in input_imgs:\n",
    "      #crop the center section ~> 1400W * 1840H\n",
    "      with Image.open(img_path) as img:\n",
    "         width, height = img.size\n",
    "         left = (width - 1400) // 2\n",
    "         top = (height - 1840) // 2\n",
    "         right = left + 1400\n",
    "         bottom = top + 1840\n",
    "         cropped = img.crop((left, top, right, bottom))\n",
    "         cropped.save(output_dir / img_path.name)\n",
    "   return\n",
    "   \n",
    "crop_imgs(raw_imgs, cropped_img_dir)\n",
    "crop_imgs(raw_labels, cropped_label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Image Format Converting \n",
    "It is recommended to convert the format of both the image and mask to TIFF format, which is suitable for the recommended Convolutional Neural Network (CNN) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code\n",
    "##ConTif\n",
    "cropped_imgs = Path(\"../images/cropped_images\").glob(\"*.jpg\")\n",
    "cropped_labels = Path(\"../images/cropped_labels\").glob(\"*.png\")\n",
    "tif_img_dir = Path(\"../images/\") / \"tif_images\"\n",
    "tif_label_dir = Path(\"../images/\") / \"tif_labels\"\n",
    "tif_img_dir.mkdir(exist_ok=True)\n",
    "tif_label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def convert_imgs_to_tif(input_imgs, output_dir) -> None:\n",
    "    for img_path in input_imgs:\n",
    "        # Convert it to Tif\n",
    "        with Image.open(img_path) as img:\n",
    "            tif_name = img_path.stem + \".tif\"\n",
    "            img.save(output_dir / tif_name, format=\"TIFF\")\n",
    "    return\n",
    "\n",
    "convert_imgs_to_tif(cropped_imgs, tif_img_dir)\n",
    "convert_imgs_to_tif(cropped_labels, tif_label_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Image Augmentation\n",
    "\n",
    "After extracting the ROI and converting the image and mask to TIFF format, we need to increase our dataset size using augmentation techniques. Here's how you can implement this method, ensuring that the image name and the respective mask name are the same:\n",
    "\n",
    "* Define Augmentation Parameters: Determine the augmentation techniques to apply, such as rotation, flipping, scaling, etc.\n",
    "\n",
    "* Loop Through Images: Iterate through each image and its corresponding mask.\n",
    "\n",
    "* Apply Augmentation: Apply the defined augmentation techniques to both the image and its mask.\n",
    "\n",
    "* Save Augmented Images: Save the augmented images and their masks with the same names as the original images and masks.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/image-12.png\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from scipy.ndimage import rotate, gaussian_filter\n",
    "from skimage.util import random_noise\n",
    "from skimage.exposure import adjust_gamma, rescale_intensity\n",
    "\n",
    "# Define functions for each operation\n",
    "\n",
    "def rotation(image, seed):\n",
    "    random.seed(seed)\n",
    "    angle = random.uniform(-180, 180)\n",
    "    return rotate(image, angle, reshape=False, mode='reflect')\n",
    "\n",
    "def h_flip(image, seed):\n",
    "    random.seed(seed)\n",
    "    return np.fliplr(image) if random.random() > 0.5 else image\n",
    "\n",
    "def v_flip(image, seed):\n",
    "    random.seed(seed)\n",
    "    return np.flipud(image) if random.random() > 0.5 else image\n",
    "\n",
    "def add_noise(image, seed):\n",
    "    np.random.seed(seed)\n",
    "    noisy_img = random_noise(image, mode='gaussian', var=0.01)\n",
    "    return np.clip(noisy_img, 0, 1)\n",
    "\n",
    "def adjust_brightness(image, seed):\n",
    "    random.seed(seed)\n",
    "    gamma = random.uniform(0.8, 1.2)\n",
    "    bright_img = adjust_gamma(image, gamma)\n",
    "    return np.clip(bright_img, 0, 1)\n",
    "\n",
    "def adjust_contrast(image, seed):\n",
    "    random.seed(seed)\n",
    "    factor = random.uniform(0.8, 1.2)\n",
    "    contrast_img = rescale_intensity(image, in_range='image', out_range=(0, 1))\n",
    "    mean = np.mean(contrast_img)\n",
    "    contrast_img = np.clip((contrast_img - mean) * factor + mean, 0, 1)\n",
    "    return contrast_img\n",
    "\n",
    "def gaussian_blur(image, seed):\n",
    "    random.seed(seed)\n",
    "    sigma = random.uniform(0.5, 1.5)\n",
    "    blurred_img = gaussian_filter(image, sigma=(sigma, sigma, 0))  # No blur on channels\n",
    "    return blurred_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TASK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0003446.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0002687.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0003310.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0003318.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0003440.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0002931.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0003006.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0002955.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0003210.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0003098.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0003182.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0003362.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image0002743.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:01<00:09,  1.97s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "###Use the functions to implement the augmentation for both images and masks\n",
    "transformations = {\n",
    "    'rot': rotation,\n",
    "    'hflip': h_flip,\n",
    "    'vflip': v_flip,\n",
    "    \"noise\": add_noise,\n",
    "    \"brightness\": adjust_brightness,\n",
    "    \"contrast\": adjust_contrast,\n",
    "    # \"blur\": gaussian_blur\n",
    "}\n",
    "tif_imgs = Path(\"../images/tif_images\").glob(\"*.tif\")\n",
    "tif_labels = Path(\"../images/tif_labels\").glob(\"*.tif\")\n",
    "augmented_img_dir = Path(\"../images/\") / \"augmented_images\"\n",
    "augmented_label_dir = Path(\"../images/\") / \"augmented_labels\"\n",
    "augmented_img_dir.mkdir(exist_ok=True)\n",
    "augmented_label_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for img_path, label_path in zip(tif_imgs, tif_labels):\n",
    "    print(f\"{img_path.name}\")\n",
    "    img = np.array(Image.open(img_path))\n",
    "    label = np.array(Image.open(label_path))\n",
    "\n",
    "    for t_name, t_func in tqdm(transformations.items()):\n",
    "        seed = random.randint(0, 10000)  # Same seed for image and mask\n",
    "\n",
    "        aug_img = t_func(img, seed)\n",
    "        aug_msk = t_func(label, seed)\n",
    "\n",
    "        # Save augmented versions\n",
    "        aug_img_pil = Image.fromarray(aug_img.astype(np.uint8))\n",
    "        aug_label_pil = Image.fromarray(aug_msk.astype(np.uint8))\n",
    "        aug_img_pil.save(augmented_img_dir / f\"{t_name}_{img_path.name}\")\n",
    "        aug_label_pil.save(augmented_label_dir / f\"{t_name}_{label_path.name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kip-P21iSh3B-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
