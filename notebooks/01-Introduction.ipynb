{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g0x0NRrLklQ"
      },
      "source": [
        "# 1. Introduction & Motivation\n",
        "Let's start by understanding where we are and what we aim to achieve. In this course, we'll explore the concept of tool wear in manufacturing. Tool wear happens when cutting tools gradually deteriorate due to regular use. This deterioration affects both product quality and productivity. It leads to inaccuracies in dimensions, rough surfaces, defects in products, and increased cutting forces. Managing tool wear is crucial for improving efficiency and maintaining quality in manufacturing processes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcEiGqYTLklS"
      },
      "source": [
        "## 1.1. Tool Wear\n",
        "Flank wear develops as a result of the friction between the tool's flank face and the surface of the workpiece being machined. This friction causes the cutting edge to deteriorate, affecting the precision of dimensions and the quality of surface finish. In real-world applications, flank wear serves as the primary indicator for evaluating tool wear.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"Images/image.png?raw=1\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
        "</div>\n",
        "\n",
        "The flank wear, as depicted in the image, stands out as the most commonly referenced wear parameter in monitoring machining processes. Both the average and maximum values of flank wear play crucial roles in assessing tool life. These metrics provide valuable insights into the tool's performance and help determine when maintenance or replacement is necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOhCtxGuLklS"
      },
      "source": [
        "## 1.2. Tool wear inspection\n",
        "There are two primary methods for inspecting tool wear:\n",
        "\n",
        "* Direct Measurement: This method involves physically measuring the wear on the tool using specialized equipment such as calipers, micrometers, or optical devices. Direct measurement provides precise data but may require pausing the machining process for inspection.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"Images/image-6.png?raw=1\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
        "</div>\n",
        "\n",
        "* Indirect Measurement: In this method, tool wear is inferred based on other observable parameters such as cutting forces, vibrations, surface roughness, or changes in cutting sound. Indirect measurement techniques are often non-intrusive and can be performed while the machining process is ongoing, allowing for real-time monitoring of tool wear. However, they may be less accurate than direct measurements.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"Images/image-5.png?raw=1\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gq5TijyiLklT"
      },
      "source": [
        "# 2. Data collection\n",
        "\n",
        "In this project, we utilize a direct inspection method employing an optical sensor, specifically a smart camera integrated into the milling machine, for tool wear inspection. In the image below, you can observe the different parts of the camera, as well as the cutting tool.\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"Images/image-8.png?raw=1\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
        "</div>\n",
        "\n",
        "The objective is to conduct milling operations using the cutting tool on a C45 workpiece under various parameters and observe the wear over the course of cutting time. The video depicts a single test session capturing the milling process.\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"Images/image-9.gif?raw=1\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
        "</div>\n",
        "\n",
        "After each milling operation, the cutting tool will reposition itself and move in front of the camera to capture images of all teeth (4 images).\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"Images/image-7.gif?raw=1\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
        "</div>\n",
        "\n",
        "After collecting the images, the next step is to detect wear on the cutting tool. To achieve this, we require a segmentation algorithm. However, before training the algorithm, we need to generate a training dataset. Since supervised learning method is preferred for this task, we must start by manually labeling the wear areas in the images. There are several open-source software options available for this purpose, but I recommend using the Image Labeler tool in MATLAB.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5oSGMy5LklU"
      },
      "source": [
        "# 3. Image Labelling\n",
        "\n",
        "## 3.1. Download training data set\n",
        "\n",
        "To begin our exploration into image labelling, we'll start by downloading a set of training images. You can find the dataset containing 35 images at this link: https://github.com/EhsanWBK/KIPII"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rhHnGFELklU"
      },
      "source": [
        "## 3.2. Image labelling\n",
        "\n",
        "Now, let's dive into the process of labelling images using the Image Labeler app in MATLAB. This step-by-step guide will help you annotate the wear sites within the images effectively.\n",
        "\n",
        "* Open MATLAB and Launch the Image Labeler App:\n",
        "    * Navigate to the APPS tab.\n",
        "    * Click on Image Labeler.\n",
        "* Import Images:\n",
        "    * In the Label Toolbar within the Image Labeler app, select Import.\n",
        "    * Choose From File and select the images you downloaded earlier.\n",
        "* Define Pixel Labels:\n",
        "    * In the ROI Labels section, select Label.\n",
        "    * Choose Pixel label and add a label name (e.g., \"Wear Site\").\n",
        "* Annotation Process:\n",
        "    * Use the Polygon tool to mark the wear areas within the images accurately.\n",
        "* Save Your Progress:\n",
        "    * Save the session by clicking on the save icon or using the shortcut Ctrl + S.\n",
        "    * This will create an imageLabellingSession.mat file, preserving your annotations.\n",
        "* Export Labelled Images:\n",
        "    * Once you've finished annotating all the images, it's time to export the ground truth data.\n",
        "    * In the Label Toolbar, select Export to File.\n",
        "<div style=\"text-align: center;\">\n",
        "    <img src=\"Images/image-10.png?raw=1\" alt=\"Alt text\" style=\"display: block; margin: 0 auto;\">\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0UXsSiILklU"
      },
      "source": [
        "## 3.3. Converting Ground Truth to Mask\n",
        "To convert the ground truth annotations into masks, we will apply linearly distributed thresholds to obtain the original class values. This process allows us to translate the labelled regions into binary masks, facilitating further analysis and model training.\n",
        "\n",
        "* TASK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2my6SD04LklV",
        "outputId": "d461dc2a-5e0b-4fa0-bcdf-71fbcc29925e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size:  35\n",
            "Found Colors (unique greyscale values [0..255]):  111\n",
            "Minimum Threshold: 0\n",
            "Maximum Threshold: 255\n",
            "New greyscale values:  [  0. 255.]\n"
          ]
        }
      ],
      "source": [
        "#import libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Ordnerpfade\n",
        "read_directory = \"../images/raw_labels\"\n",
        "write_directory = \"../images/raw_labels_binary\"\n",
        "num_classes = 2\n",
        "\n",
        "# Zielordner erstellen\n",
        "os.makedirs(write_directory, exist_ok=True)\n",
        "\n",
        "# Dataset size\n",
        "img_name_list = sorted(os.listdir(read_directory))\n",
        "img_name_list = [img for img in img_name_list if  \"Label\" in img and \"image\" in img]\n",
        "print('Dataset size: ', len(img_name_list))\n",
        "\n",
        "# Find unique colors and list them\n",
        "uniqueColors = set()\n",
        "for img_name in img_name_list:\n",
        "    img_path = os.path.join(read_directory, img_name)\n",
        "    img = cv2.imread(img_path, flags=0)  # Open image in greyscale mode\n",
        "    uniqueColors |= set(np.unique(img))\n",
        "print(\"Found Colors (unique greyscale values [0..255]): \", len(uniqueColors))\n",
        "\n",
        "# Categorize using thresholds\n",
        "minimum = int(min(uniqueColors))\n",
        "maximum = int(max(uniqueColors))\n",
        "print('Minimum Threshold: ' + str(minimum))\n",
        "print('Maximum Threshold: ' + str(maximum))\n",
        "\n",
        "# Generate linearly distributed thresholds\n",
        "thresholds = np.linspace(start=minimum, stop=maximum + 1, num=num_classes + 1)\n",
        "\n",
        "# Generate linearly distributed classes [0..255]\n",
        "colorClasses = np.linspace(start=0, stop=255, num=num_classes)\n",
        "print(\"New greyscale values: \", colorClasses)\n",
        "\n",
        "# Apply thresholds on masks\n",
        "for img_name in img_name_list:\n",
        "\n",
        "    img_path = os.path.join(read_directory, img_name)\n",
        "    img = cv2.imread(img_path, flags=0)\n",
        "\n",
        "    # Leeres Ausgabebild erzeugen\n",
        "    new_img = np.zeros_like(img, dtype=np.uint8)\n",
        "\n",
        "    # Schwellenwert-Klassifizierung\n",
        "    for i in range(num_classes):\n",
        "        lower = thresholds[i]\n",
        "        upper = thresholds[i + 1]\n",
        "        mask = (img >= lower) & (img < upper)\n",
        "        new_img[mask] = colorClasses[i]\n",
        "\n",
        "    # Ergebnisbild speichern\n",
        "    out_path = os.path.join(write_directory, img_name)\n",
        "    cv2.imwrite(out_path, new_img)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "kip-P21iSh3B-py3.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
